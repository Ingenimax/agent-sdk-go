# Agent SDK CLI Environment Variables
# Copy this file to .env and set your actual values

# LLM Provider Selection (openai, anthropic, vertex, ollama, vllm)
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com
AZURE_OPENAI_REGION=eastus
AZURE_OPENAI_RESOURCE_NAME=your-resource-name
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# Google Vertex AI Configuration
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account.json
GOOGLE_CLOUD_PROJECT=your-google-cloud-project-id

# Ollama Configuration (for local models)
OLLAMA_BASE_URL=http://localhost:11434

# vLLM Configuration (for local inference server)
VLLM_BASE_URL=http://localhost:8000

# Tool Configuration
GOOGLE_API_KEY=your_google_api_key_for_search
GOOGLE_SEARCH_ENGINE_ID=your_google_search_engine_id
GITHUB_TOKEN=your_github_personal_access_token

# Tracing Configuration (optional)
LANGFUSE_ENABLED=false
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_ENVIRONMENT=development

# Redis Configuration (optional, for distributed memory)
REDIS_URL=localhost:6379
REDIS_PASSWORD=
REDIS_DB=0

# Logging
LOG_LEVEL=info
